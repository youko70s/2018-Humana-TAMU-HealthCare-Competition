# -*- coding: utf-8 -*-
"""
Created on Sun Oct  7 18:01:07 2018

@author: youko
"""
##import packages needed 
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from pprint import pprint
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import make_gaussian_quantiles
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt
from sklearn.utils.fixes import signature

##setting n_estimators and learning rate
myData=pd.read_csv('deleted_numerical_data_full.csv')
del myData['Unnamed: 0']
##split the whole data set in to Active and InActive
Active=myData[myData['AMI_FLAG']==1]
InActive=myData[myData['AMI_FLAG']==0]
##split Active and InActive into test dataset and training set
trA, tsA = train_test_split(Active, test_size=0.382)
trIn, tsIn = train_test_split(InActive, test_size=(2726*1.62)/97274)
##combine the test dataframe
frames = [tsA, tsIn]
test_set = pd.concat(frames)

attributes=list(myData.columns.values)
attributes.remove('AMI_FLAG')
attributes.remove('ID')
target=['AMI_FLAG']
X_test=pd.DataFrame(test_set, columns=attributes)
Y_test=pd.DataFrame(test_set, columns=target)

##====================================================================
##try it on one subsample
remain_trIn,chosen_trIn=train_test_split(trIn, test_size=len(trA)/len(trIn))
frames = [trA, chosen_trIn]
subsample = pd.concat(frames)
X_train = pd.DataFrame(subsample, columns=attributes)
Y_train=pd.DataFrame(subsample, columns=target) 
bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=20, min_samples_leaf=5),
                         algorithm="SAMME",
                         n_estimators=50, learning_rate=0.5)
bdt.fit(X_train, Y_train)
pred=bdt.predict(X_test)

matrix =confusion_matrix(Y_test,pred)
print(matrix)
metrics.roc_auc_score(Y_test,pred)
##=====================================================================
#n_estimators=400
#learning_rate=1.0
'''
Adapredict_value=[]
remain_trIn=trIn
bdtscore=[]
for i in range(0,5,1):
    trIn=remain_trIn
    remain_trIn,chosen_trIn=train_test_split(trIn, test_size=len(trA)/len(remain_trIn))
##bind the chosen_trIn and trA to create a subsample
    frames = [trA, chosen_trIn]
    subsample = pd.concat(frames)
##get X_train and Y_train
    
    X_train = pd.DataFrame(subsample, columns=attributes)
    Y_train=pd.DataFrame(subsample, columns=target)  
##build the random forest tree model
    '''#here the parameters?
    '''
    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=20, min_samples_leaf=5),
                         algorithm="SAMME",
                         n_estimators=200, learning_rate=0.8)
    bdt.fit(X_train, Y_train)
    
    Adapredict_value.append(bdt.predict(X_test))
    bdtscore.append(bdt.score(X_test,Y_test))
    
##apply the majority voting scheme for the prediction results generated by subsamples
df = pd.DataFrame(Adapredict_value)
Adap=df.sum(axis=0)  
Adap=Adap.to_frame()
Adap.index=test_set.index
Adap.columns = ['votes']

def label (row):
   if row['votes'] >24:
      return 1
   else:
      return 0
   return 'Other'
Adap['Label']  = Adap.apply (lambda row: label (row),axis=1)

print("Accuracy:",metrics.accuracy_score(Y_test, Adap['Label']))
#trIn=remain_trIn
#remain_trIn,chosen_trIn=train_test_split(trIn, test_size=len(trA)/len(trIn))
##bind the chosen_trIn and trA to create a subsample
#frames = [trA, chosen_trIn]
#ubsample = pd.concat(frames)
#subsample = pd.concat(frames)
##get X_train and Y_train
    
#X_train = pd.DataFrame(subsample, columns=attributes)
#Y_train=pd.DataFrame(subsample, columns=target)  
##build the Adaboost model
#bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=20, min_samples_leaf=5),
                        # algorithm="SAMME",
                       #  n_estimators=200, learning_rate=0.8)
#bdt.fit(X_train, Y_train)

#pred=bdt.predict(X_test)
#bdt.score(X_test,Y_test)
'''
